{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('http://rasmuskyng.com/am221_spring18/psets/hw7/banknotes.data',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels\n",
    "df[4] = 2 * df[4] - 1\n",
    "\n",
    "# get features and labels\n",
    "x_np = np.array(df.iloc[:,:4])\n",
    "y_np = np.expand_dims(np.array(df[4]),axis=1)\n",
    "n,d = x_np.shape\n",
    "\n",
    "# hyper parameters\n",
    "lam = 50\n",
    "t = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.DoubleTensor(x_np),requires_grad=False)\n",
    "y = Variable(torch.DoubleTensor(y_np),requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(w_b_xi, lr, t):\n",
    "    # define variables for gradient descent\n",
    "    w_np, b_np, xi_np = w_b_xi[:d], w_b_xi[d], w_b_xi[d+1:]\n",
    "    w = Variable(torch.DoubleTensor(w_np),requires_grad=True)\n",
    "    b = Variable(torch.DoubleTensor(b_np),requires_grad=True)\n",
    "    xi = Variable(torch.DoubleTensor(xi_np),requires_grad=True)\n",
    "    \n",
    "    # run gradient descent\n",
    "    for i in range(10000):\n",
    "        # calculate barrier objective\n",
    "        barrier_objective = t * (0.5 * w.norm() ** 2 + lam * torch.sum(xi)) \\\n",
    "                      - torch.sum(torch.log(y * x @ w + b + xi - 1)) \\\n",
    "                      - torch.sum(torch.log(xi))\n",
    "        # run back propagation\n",
    "        barrier_objective.backward()\n",
    "        # update the parameters\n",
    "        w.data -= lr * w.grad.data\n",
    "        b.data -= lr * b.grad.data\n",
    "        xi.data -= lr * xi.grad.data\n",
    "\n",
    "        # manually zero the gradients after running the backward pass\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "        xi.grad.data.zero_()\n",
    "        \n",
    "    return np.vstack([w.data.numpy(),np.expand_dims(b.data.numpy(),1),xi.data.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X,lam):\n",
    "    # calculate the true objective\n",
    "    w, b, xi = X[:d], X[d], X[d+1:]\n",
    "    return 1/2 * np.linalg.norm(w, ord=2) ** 2 + lam * np.sum(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(X,x,y):\n",
    "    # calculate the accuracy\n",
    "    w, b, xi = X[:d], X[d], X[d+1:]\n",
    "    return np.mean(y * (x @ w + b) >= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n",
      "0\n",
      "t: 1 | objective: 136865.62103624135 | classification accuracy: 0.37244897959183676\n",
      "1\n",
      "t: 1.1 | objective: 136529.417169686 | classification accuracy: 0.5342565597667639\n",
      "2\n",
      "t: 1.2100000000000002 | objective: 136192.2125845217 | classification accuracy: 0.6399416909620991\n",
      "3\n",
      "t: 1.3310000000000004 | objective: 135854.28418061612 | classification accuracy: 0.7004373177842566\n",
      "4\n",
      "t: 1.4641000000000006 | objective: 135515.7755352815 | classification accuracy: 0.7419825072886297\n",
      "5\n",
      "t: 1.6105100000000008 | objective: 135176.77923031317 | classification accuracy: 0.7638483965014577\n",
      "6\n",
      "t: 1.771561000000001 | objective: 134837.36406482928 | classification accuracy: 0.7806122448979592\n",
      "7\n",
      "t: 1.9487171000000014 | objective: 134497.58434500627 | classification accuracy: 0.7981049562682215\n",
      "8\n",
      "t: 2.1435888100000016 | objective: 134157.48430887505 | classification accuracy: 0.8068513119533528\n",
      "9\n",
      "t: 2.357947691000002 | objective: 133817.1008436097 | classification accuracy: 0.8192419825072886\n",
      "10\n",
      "t: 2.5937424601000023 | objective: 133476.4652601572 | classification accuracy: 0.8279883381924198\n",
      "11\n",
      "t: 2.853116706110003 | objective: 133135.6044981562 | classification accuracy: 0.8309037900874635\n",
      "12\n",
      "t: 3.1384283767210035 | objective: 132794.54197736568 | classification accuracy: 0.8418367346938775\n",
      "13\n",
      "t: 3.4522712143931042 | objective: 132453.29822176174 | classification accuracy: 0.8469387755102041\n",
      "14\n",
      "t: 3.797498335832415 | objective: 132111.89133174712 | classification accuracy: 0.8534985422740525\n",
      "15\n",
      "t: 4.177248169415656 | objective: 131770.33735120686 | classification accuracy: 0.8556851311953353\n",
      "16\n",
      "t: 4.594972986357222 | objective: 131428.65055941133 | classification accuracy: 0.8600583090379009\n",
      "17\n",
      "t: 5.054470284992944 | objective: 131086.84370767354 | classification accuracy: 0.8637026239067055\n",
      "18\n",
      "t: 5.559917313492239 | objective: 130744.92821437202 | classification accuracy: 0.8673469387755102\n",
      "19\n",
      "t: 6.115909044841463 | objective: 130402.91432789678 | classification accuracy: 0.869533527696793\n",
      "20\n",
      "t: 6.72749994932561 | objective: 130060.81126439998 | classification accuracy: 0.8717201166180758\n",
      "21\n",
      "t: 7.400249944258172 | objective: 129718.62732541031 | classification accuracy: 0.8731778425655977\n",
      "22\n",
      "t: 8.140274938683989 | objective: 129376.36999910967 | classification accuracy: 0.8746355685131195\n",
      "23\n",
      "t: 8.954302432552389 | objective: 129034.04604817541 | classification accuracy: 0.8760932944606414\n",
      "24\n",
      "t: 9.849732675807628 | objective: 128691.66158644333 | classification accuracy: 0.8760932944606414\n",
      "1.5\n",
      "0\n",
      "t: 10.834705943388391 | objective: 128349.22214617081 | classification accuracy: 0.8775510204081632\n",
      "1\n",
      "t: 16.252058915082586 | objective: 128006.59674384505 | classification accuracy: 0.8775510204081632\n",
      "2\n",
      "t: 24.37808837262388 | objective: 127663.84731847458 | classification accuracy: 0.8775510204081632\n",
      "3\n",
      "t: 36.56713255893582 | objective: 127321.0150638374 | classification accuracy: 0.8775510204081632\n",
      "4\n",
      "t: 54.85069883840373 | objective: 126978.12744488848 | classification accuracy: 0.8775510204081632\n",
      "5\n",
      "t: 82.2760482576056 | objective: 126635.2027984988 | classification accuracy: 0.8782798833819242\n",
      "6\n",
      "t: 123.41407238640839 | objective: 126292.25337927244 | classification accuracy: 0.8782798833819242\n",
      "7\n",
      "t: 185.12110857961258 | objective: 125949.28738480997 | classification accuracy: 0.8782798833819242\n",
      "8\n",
      "t: 277.68166286941886 | objective: 125606.31030662653 | classification accuracy: 0.8782798833819242\n",
      "9\n",
      "t: 416.52249430412826 | objective: 125263.32583610328 | classification accuracy: 0.8782798833819242\n",
      "10\n",
      "t: 624.7837414561924 | objective: 124920.33648554892 | classification accuracy: 0.8782798833819242\n",
      "11\n",
      "t: 937.1756121842886 | objective: 124577.34408019487 | classification accuracy: 0.8782798833819242\n",
      "12\n",
      "t: 1405.763418276433 | objective: 124234.35051672532 | classification accuracy: 0.8790087463556852\n",
      "13\n",
      "t: 2108.6451274146493 | objective: 123891.35685854408 | classification accuracy: 0.8797376093294461\n",
      "14\n",
      "t: 3162.967691121974 | objective: 123548.36238182496 | classification accuracy: 0.8811953352769679\n",
      "15\n",
      "t: 4744.451536682961 | objective: 123205.36730142016 | classification accuracy: 0.8811953352769679\n",
      "16\n",
      "t: 7116.677305024441 | objective: 122862.37181748544 | classification accuracy: 0.8811953352769679\n",
      "17\n",
      "t: 10675.015957536662 | objective: 122519.3760639305 | classification accuracy: 0.8811953352769679\n",
      "18\n",
      "t: 16012.523936304991 | objective: 122176.38013028956 | classification accuracy: 0.8811953352769679\n",
      "19\n",
      "t: 24018.785904457487 | objective: 121833.38407643854 | classification accuracy: 0.8811953352769679\n",
      "20\n",
      "t: 36028.17885668623 | objective: 121490.38794242527 | classification accuracy: 0.8819241982507289\n",
      "21\n",
      "t: 54042.26828502935 | objective: 121147.39175503905 | classification accuracy: 0.8811953352769679\n",
      "22\n",
      "t: 81063.40242754403 | objective: 120804.39553220168 | classification accuracy: 0.8811953352769679\n",
      "23\n",
      "t: 121595.10364131605 | objective: 120461.39928590394 | classification accuracy: 0.8819241982507289\n",
      "24\n",
      "t: 182392.65546197406 | objective: 120118.40302417018 | classification accuracy: 0.8826530612244898\n",
      "2\n",
      "0\n",
      "t: 273588.9831929611 | objective: 119775.40675236995 | classification accuracy: 0.8826530612244898\n",
      "1\n",
      "t: 547177.9663859222 | objective: 119432.4104694656 | classification accuracy: 0.8826530612244898\n",
      "2\n",
      "t: 1094355.9327718443 | objective: 119089.41418229898 | classification accuracy: 0.8826530612244898\n",
      "3\n",
      "t: 2188711.8655436886 | objective: 118746.41789338531 | classification accuracy: 0.8833819241982507\n",
      "4\n",
      "t: 4377423.731087377 | objective: 118403.42160399725 | classification accuracy: 0.8841107871720116\n",
      "5\n",
      "t: 8754847.462174755 | objective: 118060.42531469913 | classification accuracy: 0.8848396501457726\n",
      "6\n",
      "t: 17509694.92434951 | objective: 117717.42519839175 | classification accuracy: 0.8848396501457726\n",
      "7\n",
      "t: 35019389.84869902 | objective: 117374.4250817147 | classification accuracy: 0.8848396501457726\n",
      "8\n",
      "t: 70038779.69739804 | objective: 117031.42496508779 | classification accuracy: 0.8848396501457726\n",
      "9\n",
      "t: 140077559.39479607 | objective: 116688.42484848999 | classification accuracy: 0.8848396501457726\n",
      "10\n",
      "t: 280155118.78959215 | objective: 116345.42473177887 | classification accuracy: 0.8848396501457726\n",
      "11\n",
      "t: 560310237.5791843 | objective: 116002.42461507906 | classification accuracy: 0.8848396501457726\n",
      "12\n",
      "t: 1120620475.1583686 | objective: 115659.42449840144 | classification accuracy: 0.8848396501457726\n",
      "13\n",
      "t: 2241240950.316737 | objective: 115316.42438174725 | classification accuracy: 0.8848396501457726\n",
      "14\n",
      "t: 4482481900.633474 | objective: 114973.42426511573 | classification accuracy: 0.8848396501457726\n",
      "15\n",
      "t: 8964963801.266949 | objective: 114630.42414850737 | classification accuracy: 0.8848396501457726\n",
      "16\n",
      "t: 17929927602.533897 | objective: 114287.42403192236 | classification accuracy: 0.8848396501457726\n",
      "17\n",
      "t: 35859855205.067795 | objective: 113944.42391536062 | classification accuracy: 0.8848396501457726\n",
      "18\n",
      "t: 71719710410.13559 | objective: 113601.42379882222 | classification accuracy: 0.8848396501457726\n",
      "19\n",
      "t: 143439420820.27118 | objective: 113258.4236823071 | classification accuracy: 0.8848396501457726\n",
      "20\n",
      "t: 286878841640.54236 | objective: 112915.42356581529 | classification accuracy: 0.8848396501457726\n",
      "21\n",
      "t: 573757683281.0847 | objective: 112572.42344934672 | classification accuracy: 0.8848396501457726\n",
      "22\n",
      "t: 1147515366562.1694 | objective: 112229.42333290147 | classification accuracy: 0.8848396501457726\n",
      "23\n",
      "t: 2295030733124.339 | objective: 111886.4232164795 | classification accuracy: 0.8848396501457726\n",
      "24\n",
      "t: 4590061466248.678 | objective: 111543.42310008076 | classification accuracy: 0.8848396501457726\n",
      "5\n",
      "0\n",
      "t: 9180122932497.355 | objective: 111200.42298370531 | classification accuracy: 0.8848396501457726\n",
      "1\n",
      "t: 45900614662486.78 | objective: 110857.42286735312 | classification accuracy: 0.8848396501457726\n",
      "2\n",
      "t: 229503073312433.9 | objective: 110514.4227510242 | classification accuracy: 0.8848396501457726\n",
      "3\n",
      "t: 1147515366562169.5 | objective: 110171.42263471855 | classification accuracy: 0.8848396501457726\n",
      "4\n",
      "t: 5737576832810848.0 | objective: 109828.42251843613 | classification accuracy: 0.8848396501457726\n",
      "5\n",
      "t: 2.868788416405424e+16 | objective: 109485.42240217693 | classification accuracy: 0.8848396501457726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "t: 1.434394208202712e+17 | objective: 109142.42228594101 | classification accuracy: 0.8848396501457726\n",
      "7\n",
      "t: 7.17197104101356e+17 | objective: 108799.4221697283 | classification accuracy: 0.8848396501457726\n",
      "8\n",
      "t: 3.58598552050678e+18 | objective: 108456.42205353882 | classification accuracy: 0.8848396501457726\n",
      "9\n",
      "t: 1.79299276025339e+19 | objective: 108113.42193737258 | classification accuracy: 0.8848396501457726\n",
      "10\n",
      "t: 8.96496380126695e+19 | objective: 107770.42182122957 | classification accuracy: 0.8848396501457726\n",
      "11\n",
      "t: 4.482481900633475e+20 | objective: 107427.42170510975 | classification accuracy: 0.8848396501457726\n",
      "12\n",
      "t: 2.2412409503167375e+21 | objective: 107084.42158901317 | classification accuracy: 0.8848396501457726\n",
      "13\n",
      "t: 1.1206204751583688e+22 | objective: 106741.42147293978 | classification accuracy: 0.8848396501457726\n",
      "14\n",
      "t: 5.6031023757918434e+22 | objective: 106398.42135688958 | classification accuracy: 0.8848396501457726\n",
      "15\n",
      "t: 2.8015511878959216e+23 | objective: 106055.4212408626 | classification accuracy: 0.8848396501457726\n",
      "16\n",
      "t: 1.4007755939479608e+24 | objective: 105712.4211248588 | classification accuracy: 0.8848396501457726\n",
      "17\n",
      "t: 7.003877969739804e+24 | objective: 105369.42100887818 | classification accuracy: 0.8848396501457726\n",
      "18\n",
      "t: 3.501938984869902e+25 | objective: 105026.42089292077 | classification accuracy: 0.8848396501457726\n",
      "19\n",
      "t: 1.750969492434951e+26 | objective: 104683.42077698653 | classification accuracy: 0.8848396501457726\n",
      "20\n",
      "t: 8.754847462174755e+26 | objective: 104340.42066107546 | classification accuracy: 0.8848396501457726\n",
      "21\n",
      "t: 4.377423731087377e+27 | objective: 103997.42054518756 | classification accuracy: 0.8848396501457726\n",
      "22\n",
      "t: 2.1887118655436885e+28 | objective: 103654.42042932284 | classification accuracy: 0.8848396501457726\n",
      "23\n",
      "t: 1.0943559327718443e+29 | objective: 103311.42031348129 | classification accuracy: 0.8848396501457726\n",
      "24\n",
      "t: 5.471779663859221e+29 | objective: 102968.42019766285 | classification accuracy: 0.8848396501457726\n",
      "10\n",
      "0\n",
      "t: 2.735889831929611e+30 | objective: 102625.42008186759 | classification accuracy: 0.8848396501457726\n",
      "1\n",
      "t: 2.735889831929611e+31 | objective: 102282.41996609548 | classification accuracy: 0.8848396501457726\n",
      "2\n",
      "t: 2.735889831929611e+32 | objective: 101939.4198503465 | classification accuracy: 0.8848396501457726\n",
      "3\n",
      "t: 2.7358898319296114e+33 | objective: 101596.4197346207 | classification accuracy: 0.8848396501457726\n",
      "4\n",
      "t: 2.735889831929611e+34 | objective: 101253.41961891798 | classification accuracy: 0.8848396501457726\n",
      "5\n",
      "t: 2.735889831929611e+35 | objective: 100910.41950323842 | classification accuracy: 0.8841107871720116\n",
      "6\n",
      "t: 2.735889831929611e+36 | objective: 100567.41938758196 | classification accuracy: 0.8841107871720116\n",
      "7\n",
      "t: 2.7358898319296115e+37 | objective: 100224.41927194865 | classification accuracy: 0.8841107871720116\n",
      "8\n",
      "t: 2.7358898319296115e+38 | objective: 99881.41915633842 | classification accuracy: 0.8841107871720116\n",
      "9\n",
      "t: 2.7358898319296115e+39 | objective: 99538.41904075131 | classification accuracy: 0.8841107871720116\n",
      "10\n",
      "t: 2.7358898319296115e+40 | objective: 99195.4189251873 | classification accuracy: 0.8841107871720116\n",
      "11\n",
      "t: 2.7358898319296115e+41 | objective: 98852.4188096464 | classification accuracy: 0.8841107871720116\n",
      "12\n",
      "t: 2.7358898319296114e+42 | objective: 98509.4186941286 | classification accuracy: 0.8841107871720116\n",
      "13\n",
      "t: 2.7358898319296114e+43 | objective: 98166.41857863391 | classification accuracy: 0.8841107871720116\n",
      "14\n",
      "t: 2.7358898319296113e+44 | objective: 97823.41846316229 | classification accuracy: 0.8833819241982507\n",
      "15\n",
      "t: 2.7358898319296113e+45 | objective: 97480.41834771374 | classification accuracy: 0.8833819241982507\n",
      "16\n",
      "t: 2.7358898319296115e+46 | objective: 97137.41823228828 | classification accuracy: 0.8833819241982507\n",
      "17\n",
      "t: 2.7358898319296115e+47 | objective: 96794.41811688589 | classification accuracy: 0.8833819241982507\n",
      "18\n",
      "t: 2.7358898319296115e+48 | objective: 96451.41800150656 | classification accuracy: 0.8833819241982507\n",
      "19\n",
      "t: 2.7358898319296116e+49 | objective: 96108.41788615032 | classification accuracy: 0.8833819241982507\n",
      "20\n",
      "t: 2.7358898319296115e+50 | objective: 95765.41777081713 | classification accuracy: 0.8833819241982507\n",
      "21\n",
      "t: 2.7358898319296116e+51 | objective: 95422.41765550697 | classification accuracy: 0.8833819241982507\n",
      "22\n",
      "t: 2.735889831929612e+52 | objective: 95079.41754021989 | classification accuracy: 0.8833819241982507\n",
      "23\n",
      "t: 2.7358898319296115e+53 | objective: 94736.41742495586 | classification accuracy: 0.8833819241982507\n",
      "24\n",
      "t: 2.7358898319296115e+54 | objective: 94393.41730971485 | classification accuracy: 0.8833819241982507\n"
     ]
    }
   ],
   "source": [
    "# initial feasible solution\n",
    "w_b_xi = np.expand_dims(np.hstack([0*np.ones(d+1),np.repeat(2,n)]),axis=1)\n",
    "\n",
    "# more hyper parameters\n",
    "eps = 0.0001\n",
    "mu = 1.1\n",
    "t = 1\n",
    "\n",
    "# barrier method\n",
    "accs = []\n",
    "mus = [1.1, 1.5, 2, 5, 10]\n",
    "for mu in mus:\n",
    "    print(mu)\n",
    "    for i in range(25):\n",
    "        w_b_xi = gradient_descent(w_b_xi,10**-8/t,t)\n",
    "        print(i)\n",
    "        print(\"t: {} | objective: {} | classification accuracy: {}\".format(t,f(w_b_xi,lam),acc(w_b_xi,x_np,y_np)))\n",
    "        t = mu * t\n",
    "    accs.append(acc(w_b_xi,x_np,y_np))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
